% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Background and Related work}\label{chapter:relatedwork}

In this chapter, we delve into the background and
related work that forms the foundation for our research on
solving small linear programming problems related to cardinality estimation.
We will talk about optimization, in particular the field
of linear programming. We will elaborate on
the most widely used algorithms and techniques to tackle this problem,
and we present some use cases and benchmarks.
A major use case of linear programming solvers is cardinality estimation, which
is a crucial step in the pipeline of query optimization.

\section{Linear Programming Fundamentals}

\subsection{Linear Programming problem}
Informally, \gls{lp} is a method to calculate the best possible outcome from a given set
of requirements. A concrete real-world application of such a method is
for instance aiming to maxmize profit in a business, given some constraints on your variables
like raw material availability, labor hours, etc.

Formally, \gls{lp} is a mathematical modeling technique in which
a linear function (called the objective function) \( z: \mathbb{R}^n \to \mathbb{R} \)
is maximized or minimized when subject to a set of linear constraints or inequalities.
A maximization \gls{lp} problem is then defined as:
\begin{align}
    \text{Maximize} \quad   & z = \mathbf{c}^T \mathbf{x} \notag            \\
    \text{subject to} \quad & \mathbf{A} \mathbf{x} \leq \mathbf{b} \notag  \\
                            & \mathbf{x} \geq \mathbf{0} \label{LP_Problem}
\end{align}
Where $n$ is the number of decision variables and $m$ is the number of constraints:
\(\mathbf{x} \in \mathbb{R}^n\) is the column vector of decision variables.
\(\mathbf{c} \in \mathbb{R}^n\) is the column vector of coefficients in the objective function.
\(\mathbf{A} \in \mathbb{R}^{m \times n}\) is the coefficient matrix in the constraints.
\(\mathbf{b} \in \mathbb{R}^m\) is the column vector of the right-hand sides of the constraints.
In the following sections, we focus on \gls{lp} problems that are maximization problems and we primarily
use the matrix representation of the problem.

To derive the setting for our contribution,
we also explore a special instance of \gls{lp} problems called packing \gls{lp}.
\subsection{Packing LP}
One LP problem class that we are dealing with is called the packing LP problem. It is a special instance where:
\( \mathbf{c}  = \mathbf{b} =  \begin{bmatrix}
    1 & 1 & \dots & 1
\end{bmatrix} \).
Our specific problem is then expressed as follows:
\begin{align}
    \text{Maximize} \quad   & \sum_{i=1}^{n} x_j \notag                                                             \\
    \text{subject to} \quad & \notag                                                                                \\
                            & \mathbf{A} \mathbf{x} \leq \mathbf{1}_m, \quad                                        \\
                            & x_i \geq 0, \quad                              & i = 1, \ldots, n \label{PLP_Problem}
\end{align}
Where $\mathbf{1}_m = \begin{bmatrix}
        1      \\
        1      \\
        \vdots \\
        1      \\
    \end{bmatrix}$


\subsection{Duality}\label{duality}

The duality theorem is an interesting result in linear programming, that
states that very instance of maximization problem has a corresponding
minimization problem called its dual problem.
The two problems are linked in an interesting way:
if one problem has an optimal solution, then so does the other,
and their optimal solutions are equal.

For instance, consider the primal-dual pair \gls{lp}:
\[
    \begin{array}{c@{\quad}c@{\quad}c}
        \begin{aligned}
            \text{maximize} \quad   & \mathbf{c}^T \mathbf{x}               \\
            \text{subject to} \quad & \mathbf{A} \mathbf{x} \leq \mathbf{b} \\
                                    & \mathbf{x} \geq 0                     \\
        \end{aligned}
         &
        \begin{array}{c}
            \longrightarrow
        \end{array}
         &
        \begin{aligned}
            \text{minimize} \quad   & \mathbf{b}^T \mathbf{y}                 \\
            \text{subject to} \quad & \mathbf{A}^T \mathbf{y} \geq \mathbf{c} \\
                                    & \mathbf{y} \geq 0                       \\
        \end{aligned}
    \end{array}
\]

\subsection{Geometric Interpretation}
In this part let's assume for simplicity that we have two decision variables
in our LP problem, i.e. $\mathbf{x} \in \mathbb{R}^2 $
is a two dimensional vector. This assumption will allow us to plot our problem on
a 2D plane. An example is shown in figure \ref{fig:lp_geom}.
The linear programming problem \ref{LP_Problem} can be understood geometrically as follows:
Each inequality in the set of constraints is represented by a line.
Therefore, the feasible region $\chi$ of any LP problem can be described as the intersection delimited
by those lines, which is called a polyhedron, or in our 2D case, a polytope.
The feasible region is the set of all feasible points, or vertices.
A feasible vertex is a point at which, when substituted into the constraints, they are satisfied.
The corners of the polytope are called vertices.
They lie in the intersection of at most $n$ constraints. If a vertex lies in the
intersection of more than $n$ lines, it is called degenerate.

\begin{figure}
    \centering
    \begin{tikzpicture}
        \begin{axis}[
                xmin=-1, xmax=7,
                ymin=-1, ymax=7,
                axis lines=center,
                axis on top=true,
                domain=0:7,
                ylabel=$y$,
                xlabel=$x$,
            ]

            % Feasible regions with semi-transparent colors
            \addplot[fill=blue, fill opacity=0.2, draw=none, domain=0:4] {4-x} \closedcycle;
            \addplot[fill=red, fill opacity=0.2, draw=none, domain=0:3] {6-2*x} \closedcycle;



            % Inequalities
            \addplot[thick, domain=0:4, blue] {4-x};
            \addplot[thick, domain=0:3, red] {6-2*x};

            % Objective function (z = 3x + 2y = 12 as an example)
            \addplot[dashed, domain=0:2, black] {2-x};
            \draw[->, thick, black] (axis cs:1,1) -- (axis cs:2,2); % Arrow indicating direction of increase

        \end{axis}
    \end{tikzpicture}
    \caption{Feasible region of the LP problem}
\end{figure}\label{fig:lp_geom}

The simplex algorithm that we will descibe later starts at an initial feasible vertex and moves along
the edges of the polytope to vertices with better objective
values until the optimal vertex is reached.


\subsection{Feasibility, unboundedness}\label{feasibility}
We described how in geometric terms, a linear programming (LP) problem is feasible if the
polytope defining its feasible region $ \chi $ is not empty.
In other words, the LP is infeasible if no feasible solution exists, or $\chi = \emptyset$.

The LP is said to have unbounded set of solutions if its
solution can be made infinitely large without violating any of its constraints in the problem.
Meaning its feasible region is infinite, or unbounded. An example is shown in Figure \ref{unbounded}.

\begin{figure}[h]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
                xlabel=\(x_1\),
                ylabel=\(x_2\),
                xmin=-1, xmax=5,
                ymin=-1, ymax=5,
                grid=both,
                minor tick num=1,
                major grid style={gray!30},
                minor grid style={gray!10},
                axis lines=middle,
                enlargelimits={abs=0.5},
                legend pos=north west,
            ]

            % Constraints
            \addplot[name path=constraint1, blue, thick, domain=0:5] {x + 1}; % x1 - x2 >= 1
            \addplot[name path=axis, draw=none, domain=0:5] {0}; % x-axis
            \addplot[blue!20] fill between[of=constraint1 and axis, soft clip={domain=0:5}];

            % Objective function (for illustration, let's assume z=3)
            \addplot[green, thick, dashed, domain=0:4] {3-x}; % x1 + x2 = 3

            % Arrow for objective function
            \draw[->, thick, green] (2,1) -- (3,0); % Arrow for the objective function

            % \legend{
            %    \(x_1 - x_2 \geq 1\),
            %    Objective function
            %}

        \end{axis}
    \end{tikzpicture}
    \caption{Graphical representation of an unbounded LP problem}
    \label{unbounded}
\end{figure}

The LP has an optimal solution, if there is a vertex \( \mathbf{x^*} \), called the optimal
vertex, such that
$\mathbf{c}^T \mathbf{x} \leq \mathbf{c}^T \mathbf{x^*} $ for all $\mathbf{x} \in \chi$.

\begin{figure}[!htb]
    \centering
    \begin{tikzpicture}[node distance=2cm, auto]
        % Define styles
        \tikzstyle{block} = [rectangle, draw, fill=blue!20, text width=6em, text centered, rounded corners, minimum height=3em]
        \tikzstyle{line} = [draw, -latex']

        % Place nodes
        \node [block] (basis) {Optimal Basis};
        \node [block, right=of basis] (solution) {Optimal Solution};
        \node [block, right=of solution] (vertex) {Optimal Vertex};

        % Draw edges
        \path [line] (basis) -- node {defines} (solution);
        \path [line] (solution) -- node {is} (vertex);

    \end{tikzpicture}
    \caption{Conceptual relationship between an optimal basis, an optimal solution,
        and an optimal vertex.}
\end{figure} \label{equivalence_terms}

\subsection{The Standard Simplex Algorithm}
In this subsection we will present the most widely used algorithm for solving
LP problems, the simplex algorithm, as introduced by George Dantzig in 1947
\parencite{dantzig1990origins}. We have implemented our version of this algorithm
in the C++ language and we use it, among others, to solve our dataset.

\subsubsection{Computational form of LP}
To be approachable by the simplex algorithm, the \gls{lp} problem
\ref{LP_Problem} needs to be cast in a
computational or standard 7form \ref{LP_Problem_Comp}, that fulfills the requirement of the
constraint matrix having to have full row rank and only equality  constraints are allowed.
To convert the inequalities to equations, we introduce slack variables
\(s_1, s_2, \dots, s_m\). After introducing those variables
let's look at the problem \ref{LP_Problem}, where the constraints are now linear equalities:

\begin{align}
    \text{Maximize} \quad   & z = \mathbf{c}^T \mathbf{x} \notag                            \\
    \text{subject to} \quad & \sum_{j=1}^{n} a_{1j} x_j + s_1 = b_1 \notag                  \\
                            & \sum_{j=1}^{n} a_{2j} x_j + s_2 = b_2 \notag                  \\
                            & \vdots \notag                                                 \\
                            & \sum_{j=1}^{n} a_{mj} x_j + s_m = b_m \label{LP_Problem_Comp} \\
                            & x_1, x_2, \dots, x_n, s_1, s_2, \dots, s_m \geq 0 \notag
\end{align}

We then have a \gls{lp} problem in the appropriate form and can be used as input for
the simplex algorithm. To develop an intuition for how this algorithm works,
it is helpful to view the strategy of the simplex algorithm as that of
successive improvements until reaching an optimum. For instance, a maximization problem is optimized when the slack
variables are “squeezed out,” maximizing the true variables’ effect on the objective
function.

\subsubsection{Defining a Basis}
So far we have used the terms feasible and optimal vertex, solution,
point interchangeably to refer
to the optimum of a LP problem. Now we will explore the concept of feasible and optimal basis. All the
concepts are however equivalent, see \ref{equivalence_terms}, yet the simplex algorithm uses the
basis terminology.

In  linear algebra, a basis of a vector space is a set of vectors that:
\begin{itemize}
    \item Spans the space: This means that every vector in the vector space
          can be expressed as a linear combination of the basis vectors.
    \item Is linearly independent: This means that no vector in the basis can be
          expressed as a linear combination of the other basis vectors.
\end{itemize}

In simpler terms, a basis provides a set of "building blocks" from which all other vectors in the
space can be constructed without any redundancy.

If an LP problem has an optimal solution, it is enough to search the finite number
of vertices of the feasible region. Every vertex, or corner point of the feasible region has at least
one set of $m$ linearly independent columns of $A$ associated with it. The set of indices
of these columns is called a basis.

A basis can be seen as a basis matrix, consisting of the
$m$ linearly independent columns of $A$ associated with it.

A feasible basis contains the indices of basic
variables. A feasible basis is a basis for which all the basic variables have
non-negative values when the other variables (non-basic variables) are set to zero.


\subsubsection{The algorithm}
As we have seen, slack variables are introduced to convert inequalities
into equations, and these slack variables can form an initial feasible basis.
In this case, the decision variables are set to zero, and the slack variables are set to
the values on the right-hand side of the constraints.
This provides a starting point for the Simplex method.

If the the right-hand side is a vector of nonnegative numbers, i.e. $mathbb{b} \geq 0 $, then
the problem is said to be initially feasible.

This constitutes a feasible dictionary (or tableau), formally defined in \parencite{chvatal1983linear}.
The simplex method then contructs a sequence of feasible dictionaries until reaching an optimum.
The rest of the steps of the simplex algorithm are broadly presented in the following:

\begin{algorithm}
    \caption{Simplex Algorithm}
    \begin{algorithmic}[1]
        \Procedure{Simplex}{$\mathbf{c}, \mathbf{A}, \mathbf{b}$}
        \State Initialize a feasible basic solution
        \While{true}
            \State Search for an entering variable (pricing)
            \If{no entering variable exists}
                \State \Return "Optimal solution found"
            \EndIf
            \State Search for a leaving variable using the minimum ratio test
            \If{no positive pivot element in the column}
                \State \Return "Unbounded"
            \EndIf
            \State Perform the pivot operation
            \State Update the basic and non-basic variables
        \EndWhile
        \EndProcedure
    \end{algorithmic}
    \label{algo:simplex_tableau}
\end{algorithm}


Let's present the methods used to perform the exchange in each step, i.e. the choice of the entering
variable and the choice of the leaving variable.

\begin{itemize}
    \item Pricing: The choice of the entering variable: we choose a non-basic variable to enter the basis
          and thus become basic. This is called Pricing. The choice usually depends on metrics
          like the largest increase in the objective function, or the largest coefficient.
          Bland's rule has been proved to guarantee termination:
          Choose the entering variable as the non-basic variable with
          the smallest index that has a negative reduced cost for a maximization problem:
          \[
              j = \min \{ j : c_j < 0 \}
          \]

    \item Ratio test: the choice of the leaving variable: we choose a basic variable to leave the basis:
          we do this by performing a ratio test.
          For the chosen entering variable, compute the ratios for all positive values in its column:
          \[
              \text{ratio}_i = \frac{b_i}{a_{ij}}
          \]
          Choose the leaving variable as the basic variable  has the smallest non-negative ratio:
          \[
              i = \min \left\{ i : \text{ratio}_i = \min_{a_{ij} > 0} \frac{b_i}{a_{ij}} \right\}
          \]
\end{itemize}

After selecting an entering variable and a leaving variable, we perform Pivoting, or
updating the tableau.

\subsubsection{Termination}
\begin{enumerate}
    \item \textit{Optimality:}
          The algorithm terminates when there are no more negative coefficients in the objective function
          row for a maximization problem (or no more candidates for entering variables).

    \item \textit{Unboundedness:}
          If all the entries in the column of the entering variable are non-positive during the pivot
          operations, the problem is unbounded.

    \item \textit{Cycling:}
          The algorithm might enter a cycle, revisiting the same basic feasible solutions. Bland's rule
          can prevent this.

    \item \textit{Maximum Iterations:}
          A set maximum number of iterations can be used to prevent indefinite running due to
          numerical issues or other unforeseen circumstances. We set a bound on number of steps in our
          implementations. This bound is equal to the maximum value a 32-bit unsigned integer can take, or
          $4294967295$.
\end{enumerate}

\subsubsection{The runtime complexity of the simplex algorithm}
%Worst case vs. average case
Since the idea of the simplex algorithm is to search the finite number of bases until a basis is
found that belongs to the optimal vertex, and there are $\binom{m}{n}$ bases, this might take
an exponential number of steps.
In fact, Klee and Minty (1972) \parencite{klee1972good} constructed a worst-case example where
$2^m -1$ iterations may be required, making the simplex'
worst-case time complexity exponential, which we denote by \( O(2^m) \).

It can be however argued that this is only one worst-case example. Indeed, the number
of iterations usually encountred in practice or even in formal experimental studies of is much lower.
With $m<50$ and $m+n<200$, where $m$ and $n$ are the number of constraints and variables in the \gls{lp}
problem respectively, Dantzig observed that the number of iterations are usually less than $3m/2$
and only rarely going to $3m$. However, there is no proof that for every
problem the simplex algorithm for
linear programming has a number of iterations or pivots that
is majorized by a polynomial function.

For packing linear programs, the worst-case time complexity of the Simplex algorithm
remains exponential, even though there exists polynomial time implementations for it.
\parencite{stille2010solution}.

\subsubsection{Time complexity analysis of one step}
Given a linear program with \( m \) constraints and \( n \) variables, the tableau for the
simplex algorithm will be of size \( (m+1) \times (n+m+1) \).
The time complexity of one iteration of the tableau simplex algorithm can be broken down as follows:

\begin{itemize}
    \item Identifying the entering variable (choosing from $m$ non-basic variables): \( O(m) \)
    \item Identifying the leaving variable: \( O(n) \)
    \item Pivoting operation: \( O(m \times n) \)
\end{itemize}

Thus, the overall time complexity of one iteration is \( O(m \times n) \).
This is considered large, especially knowing that there may be an
exponential number of iterations. This is why we proceed to define
other solution methods that
succeeded to achieve a better time performance.

\subsection{The interior point method}
The interior point method is a mathematical optimization
technique used to solve linear programming (LP) and
nonlinear programming (NLP) problems.
At its core, this method is based on the concept of iteratively
moving through the interior of the feasible region of a convex
optimization problem. Mathematically, it can be described as follows:

Consider an LP problem in standard form:

\[
    \begin{aligned}
        \text{Minimize:} \quad   & c^Tx     \\
        \text{Subject to:} \quad & Ax = b   \\
                                 & x \geq 0
    \end{aligned}
\]

Where:
\begin{align*}
     & c \text{ is a vector of coefficients representing the objective function to be minimized.} \\
     & x \text{ is a vector of decision variables.}                                               \\
     & A \text{ is a matrix representing the system of linear constraints.}                       \\
     & b \text{ is a vector of constants.}
\end{align*}

The interior point method
introduces a barrier or penalty function to the objective function,
which effectively discourages solutions near the boundary of the feasible
region. This barrier function is typically defined as $-\sum \log(x_i)$,
where $x_i$ represents the elements of the vector $x$.
The optimization problem then becomes:

\[
    \begin{aligned}
        \text{Minimize:} \quad & c^Tx - \mu \sum \log(x_i)
    \end{aligned}
\]

Where $\mu$ is a parameter controlling the trade-off between
optimizing the original objective function and staying within
the interior of the feasible region.

The key mathematical insight of the interior point method is that
as $\mu$ approaches zero, the solution converges toward the optimal
solution of the original LP problem. The method iteratively updates $\mu$
and the solution vector $x$ until a suitable solution within the interior
of the feasible region is found. This approach enables efficient and robust
optimization of linear and nonlinear programming problems, making it a
valuable tool in various fields, including engineering, economics, and
operations research.

\begin{algorithm}[H]
    \caption{Interior Point Method for Linear Programming}
    \begin{algorithmic}[1]
        \Procedure{InteriorPoint}{$A, b, c, x_0, \mu, \epsilon$}
        \State Initialize $x$ to $x_0$
        \While{not converged (e.g., $||Ax - b|| > \epsilon$)}
        \State Compute the Newton direction $d$ by solving:
        \State \quad $Hd = -(c + A^T\lambda)$
        \State \quad $Ad = b - Ax$
        \State Update the barrier parameter:
        \State \quad $\mu \leftarrow \frac{\mu}{\text{updateFactor}}$
        \State Update $x$ and $\lambda$:
        \State \quad $x \leftarrow x + \alpha d$
        \State \quad $\lambda \leftarrow \lambda + \alpha \mu Ad$
        \EndWhile
        \State \textbf{return} $x$ \Comment{Optimal solution}
        \EndProcedure
    \end{algorithmic}
\end{algorithm}

\subsubsection{Time Complexity Analysis}
The time complexity of the interior
point method for linear programming is determined by
the number of iterations required for convergence.
In practice, the number of iterations is often polynomial in
the problem size, which includes the number of decision variables and
constraints.
Each iteration involves solving a system of linear equations,
particularly: $Hd = -(c + A^T\lambda)$

Where:
\begin{itemize}
    \item $H$ is a symmetric positive definite matrix (related to the Hessian of the Lagrangian).
    \item $d$ is the Newton direction.
    \item $c$ is the vector of coefficients representing the objective function.
    \item $A$ is the constraint matrix.
    \item $\lambda$ is the vector of dual variables.
\end{itemize}


which can be done efficiently, especially if $H$ and $A$ are sparse (e.g. using Cholesky, LU decomposition).
We can express the overall time complexity
of the interior point method as follows:

\[
    O(k \cdot (f(n, m) + g(n)))
\]

Where:
\begin{itemize}
    \item $k$ is the number of iterations.
    \item $f(n, m)$ represents the cost per iteration, which is polynomial in $n$ and $m$.
    \item $g(n)$ represents any additional preprocessing or initialization costs, which are typically polynomial in $n$.
\end{itemize}
Therefore, the overall time complexity of the interior point method is polynomial.
\subsection{Revised Simplex Algorithm}
While the standard or tableau simplex algorithm maintains and updates the
entire tableau in its
dense form at each iteration, and the pivotting step of this algorithm is
highly costly as we have to update the entire matrix
using row operations.
The revised simplex
method transforms only the inverse of the basis matrix, $mathbb{B}^{-1}$, thus
reducing the amount of writing at each step and overall memory usage.
This is explained in the following mathematical proof.

\subsubsection{The algorithm}
Let's derive the mathematical proof of this algorithm:
Given a linear programming problem in standard form:
\begin{align*}
    \text{maximize} \quad   & \mathbf{c}^T \mathbf{x}           \\
    \text{subject to} \quad & \mathbf{A}\mathbf{x} = \mathbf{b} \\
                            & \mathbf{x} \geq \mathbf{0}
\end{align*}
where \( A \) is an \( m \times n \) matrix,
\( b \) is an \( m \times 1 \) vector, and
\( c \) is an \( n \times 1 \) vector.


Partition \( x \) into basic (\( x_B \)) and non-basic (\( x_N \)) variables.
Similarly, partition \( A \) into \( B \) (columns corresponding to \( x_B \))
and \( N \) (columns corresponding to \( x_N \)).

The constraints can be written as:
\begin{align*}
    Bx_B + Nx_N & = b    \\
    x_B         & \geq 0 \\
    x_N         & \geq 0
\end{align*}

From \( Bx_B + Nx_N = b \), when \( x_N = 0 \):
\[ x_B = B^{-1}b \]
This is the basic feasible solution if all entries of \( x_B \) are non-negative.

Compute the reduced costs:
\[ \bar{c}_N^T = c_N^T - c_B^T B^{-1} N \]
If all entries of \( \bar{c}_N^T \) are non-negative,
then the current basic feasible solution is optimal.

If some entries of \( \bar{c}_N^T \) are negative,
choose \( j \) such that \( \bar{c}_j < 0 \). Compute:
\[ d = B^{-1} A_j \]
If all entries of \( d \) are non-positive, the problem is unbounded.

Otherwise, compute the step length:
\[ \theta = \min \left\{ \frac{x_B[i]}{d[i]} : d[i] > 0 \right\} \]
Update the solution:
\[ x_B = x_B - \theta d \]
\[ x_j = \theta \]
and update the sets of basic and non-basic variables.

This proof elucidates that the only variables required to "recreate" exactly the tableau at
each step, without performing the costly pivotting operation are:
\begin{itemize}
    \item the indices of basic and non-basic variables
    \item $B^{-1}$ the inverse of the basis matrix. This is used to solve two types of linear equations
          during an iteration, see step 1 and 3 in \ref{algo:revised}.
          In the actual implementation, there is no need to compute or store the $B^{-1}$.
          We just use the basis matrix $B^{-1}$ to solve these linear systems of
          equations. Therefore in practice, we only store $B$.
    \item the current values of the basic variables, or the current basic feasible solution $x_B = B^{-1}b$
\end{itemize}

The algorithm is elaborated in \ref{algo:revised}. As we can see, step 1 and 3 represent the solving of
two types of systems , \gls{ftran} and \gls{btran}.

However, having to recompute the inverse of a matrix, or in our actual
implementation, solve a linear equation system may be costly.

\subsubsection{Inverting a square matrix}
For a square matrix of size \(n \times n\), the time complexity of LU
decomposition
\parencite{golub2013matrix},
which is one of the
most prominent methods to invert a matrix, is $O(n^3) $.

This is why it is desirable to employ another tool to efficiently
update the inverse of the basis matrix $B^{-1}$
without having to recompute it from scratch each time.
Such tools are called update methods,
and we will later describe the \gls{pfi},
the modified \gls{pfi} and we also describe Forrest-Tomlin update method
in the future work section.

\begin{algorithm}
    \caption{Revised Simplex Algorithm}
    \begin{enumerate}
        \item \textbf{Input:} A feasible basic solution, \( B \), \( c \), \( A \), and \( b \)
        \item \textbf{Output:} Optimal solution or a certificate of unboundedness
        \item Initialize \( B^{-1} \), the inverse of the basis matrix \( B \)
        \item \textbf{While True:}
              \begin{itemize}
                  \setlength{\itemindent}{3em}
                  \item[\textit{Step 1:}] Solve the system \( yB = c_B \) (BTRAN)
                  \item[\textit{Step 2:}] Choose an entering column. This may be any column a of
                      $A_N$ such that $ya$ is less than the corresponding component
                      of $c_N$. If there is no such column, then the current solution is optimal.
                      In other words: Choose first \( j \) such that \( c_j -yA_j > 0 \)
                      then $a=A_j$ is the enterig column.
                  \item[\textit{Step 3:}] Solve the system $Bd = a$ (FTRAN)
                  \item[\textit{Step 4:}] Let $x_B^{\ast} = B^{-1}b$ the current basic variables' values.
                      Find the largest $t$ such that \( x_B^{\ast} - td \geq 0\)
                      if there is no such $t$, then the problem is unbounded; otherwise, at least
                      one component of  \( x_B^{\ast} - td \) equals zero and the corresponding variable is leaving the basis.
                  \item[\textit{Step 5:}] Set the value of the entering variable at
                      $t$ and replace the values $x_B^{\ast}$ of the basic variables by \( x_B^{\ast} - td \).
                      Replace the leaving column of B by the entering column, and in the basis heading,
                      replace the leaving variable by the entering variable.
              \end{itemize}

        \item \textbf{Return} Optimal solution \( B^{-1}b \)
    \end{enumerate}
    \label{algo:revised}
\end{algorithm}

\subsubsection{The product form inverse update method}

We will discuss the Product Form of the Inverse (PFI), introduced by
George Dantzig \parencite{dantzig1954product}. In the revised simplex method,
there's a need to represent the inverse of the basis matrix and efficiently
solve the BTRAN and FTRAN systems in Step 1 and 3 of Algorithm \ref{algo:revised}
in each iteration to find the entering and leaving variables.

To avoid the costly reinversion of the basis matrix in each step,
we apply an INVERT operation only once at the beginning, on the initial basis
matrix $B_0$. Inverting a matrix using LU decomposition requires $O(n^3)$
operations.

Instead of solving the systems $yB = c_B$ and $Bd = a$ from
scratch, we utilize an update method known as the product form of the inverse.

Given a basis matrix \(B\) and its inverse \(B^{-1}\),
let $p$ be the index of the basic variable leaving the basis in
this step, and let the vector \(a_q\) represent the entering column,
which is the solution of the FTRAN system (see Algorithm \ref{algo:revised},
Step 3). We can express this update as follows:

\[
    \hat{B} = B + (a_q - B e_p) e_p^T = B (I + (a_q - B e_p) e_p^T) = B E
\]

Here, \(E = I + (a_q - B e_p) e_p^T\) is referred to as an \textit{eta matrix}.

In other words, if \(B_k\) denotes the basis matrix after \(k\)
iterations of the simplex method, and each \(B_k\) differs from the
preceding \(B_{k-1}\) in only one column, we have the following update equation:

\[
    B_k = B_{k-1}E_k \label{eq:basis_update}
\]

with \(E_k\) representing the identity matrix whose \(p\)th column
is replaced by \(d\), and is referred to as an \textit{eta matrix}.
Consequently, when the initial basis consists of slack variables,
we have \(B_0 = I\), and successive applications of
Equation \ref{eq:basis_update} yield:

\[
    B_k = E_1E_2 \cdot E_k \label{eq:eta_factorization}
\]

This eta factorization of \(B\) provides an optimized way
to solve the two systems:

Solving the system \(yB_k = c_B\) becomes solving:

\[
    (((yE_1)E_2) \ldots )E_{k} = c_B
\]

Solving the system \(B_kd = a\) becomes solving:

\[
    E_1(E_2( \ldots (E_{k}d))) = a
\]

\textbf{Time Complexity of Direct Solution:}
Solving the system \(yB_k = c_B\) or \(B_kd = a\)  directly using
Gaussian elimination or LU decomposition has a time complexity of \(O(m^3)\),
where \(m\) is the dimension of $B_k$, i.e. the number of rules.


\textbf{Time complexity Using Eta Factorization:}
Solving \(E_i x = y\) or  \(xE_i = y\) for x in each iteration involves
simple vector operations and matrix multiplication,
which has a time complexity of \(O(n^2)\).
Therefore, applying the eta factorization \(B_k = E_1E_2 \ldots E_k\)
takes a time complexity of \(O(kn^2)\), where $k$ is the number of eta vectors,
or the current iteration count.


\textbf{Comparing the Two Methods:}
\begin{itemize}
    \item Direct Solution: \(O(m^3)\) for both systems.
    \item Using Eta Factorization: \(O(km^2)\) for both systems,
          where \(k\) is the number of iterations.
\end{itemize}

In summary, when using the eta factorization method,
the time complexity for solving both systems becomes \(O(km^2)\),
which depends on the number of iterations (\(k\)) and the number of
constraints (\(m\)).


\subsubsection{The modified product form inverse}
The Middle Product Form (MPF) update integrates
updates in product form into the middle of factors L and U.
This update
can be described as follows:

Given:
\[ \bar{B} = LU + (aq - Bep)e^T_p \]
The transformation from \(\bar{B}\) to the form in terms of \(L\) and \(U\) is:
\[ \bar{B} = L(I + (\tilde{aq} - up)\tilde{e}^T_p )U \]
where
\[ \tilde{aq} = L^{-1}aq \]
\[ \tilde{e^T_p} = e^T_p U^{-1} \]
\[ up = Uep \]

Also:
\[ \bar{B}^{-1} = U^{-1}(I - \frac{1}{\mu} (\tilde{aq} - up)\tilde{e}^T_p )L^{-1} \]
where
\[ \mu = 1 + \tilde{e^T_p}(\tilde{aq} - up) = \hat{apq} \]

After \(k\) updates:
\[ B_k = L_0T_1T_2...TkU_0 \]
If we assume, initially \( B_0 = I \), the its LU-decomposition is also the identity
matrix:
Expressing \( B_k^{-1} \) with \( B_0 = I \):
\[ B_k^{-1} = T_k^{-1}...T_2^{-1}T_1^{-1} \]
\( T \) is a matrix that represents the update
transformation inserted into the factorized form of the basis matrix \( B \).
The explicit definition of \( T \) is:

\[ T = I + (\tilde{aq} - up)\tilde{e}^T_p \]

Breaking it down:
\begin{itemize}
    \item \( I \) is the identity matrix.
    \item \( \tilde{aq} \) is a partial FTRAN result, defined as:
          \[ \tilde{aq} = L^{-1}aq \]
    \item \( \tilde{e^T_p} \) is another partial BTRAN result, defined as:
          \[ \tilde{e^T_p} = e^T_p U^{-1} \]
    \item \( up \) is the \( p^{th} \) column of \( U \), defined as:
          \[ up = Uep \]
\end{itemize}


\section{Cardinality Estimation}\label{section:cardinality-estimate}
An important use case of linear programming solvers in the field of databases is
cardinality estimation.
In the context of query optimization, LP solvers can be useful to estimate query plan
cardinalities and provide a reliable and good enough estimate to be used in selecting
the best Join-order, and hence speeding up query execution time.
In the pipeline of query execution, cardinality estimation serves
as a cornerstone for the query optimization process.
Cardinality, defined as the number of tuples in the output,
plays a pivotal role in the selection of an optimal query plan.
Modern \gls{dbms} often rely on
cost-based query optimizers to make this selection.
For example, the SQL Server Query Optimizer
\parencite{microsoft2023cardinality} employs a
cost-based approach, aiming to minimize the estimated
processing cost of executing a query.

Enhanced cardinality estimation
can lead to more accurate cost models, which in turn results
in more efficient query execution plans.
Consequently, accurate and reliable cardinality estimates are
crucial in achieving faster query execution times.
The objective is to develop a \gls{lp}
solver designed specifically for cardinality estimation.
This solver aims to maximize a cost function that represents
the upper bound of the output size, optimizing for both
time and memory complexity.

To set the stage for our implementation, we introduce the AGM bound.

\subsection{AGM bound}
The AGM bound \parencite{atserias2013size} proves
using entropy that \[ \min_w \left( \sum_{i=1}^{k} w_i \log |R_i| \right) \]
is a tight upper bound for join size, given query graph (how the
relations are connected, if there are any shared attributes)
and relation sizes.
The dual \gls{lp} problem of the given minimzation problem, is
\[ \max \sum_{i} v_i \]
subject to:
\[ A^T \mathbf{v} \leq \log |R| \]
The dual theorem \ref{duality} states that the both problems have the same
optimal values.

This is how our \gls{lp} datasets are generated.

We start with the inequality \ref{eq:initial_inequality}. Applying the natural logarithm to both sides yields \ref{eq:log_inequality}. We then rename the variables, simplifying the inequality to \ref{eq:renamed_inequality}.
Normalizing by dividing both sides by \(r'\), we obtain \ref{eq:normalized_inequality}. This leads us to the objective function for our packing LP problem.
\begin{align}
    |a| \cdot |b|                            & \leq |R| \label{eq:initial_inequality}                                                   \\
    \ln|a| + \ln|b|                          & \leq \ln|R| \label{eq:log_inequality}                                                    \\
    a' + b'                                  & \leq r' \label{eq:renamed_inequality}                                                    \\
    \frac{1}{r'} a' + \frac{1}{r'} b'        & \leq 1 \label{eq:normalized_inequality}                                                  \\
    \text{maximize } a' + b' + c' + d' \quad & \text{s.t.} \quad \frac{1}{r'} a' + \frac{1}{r'} b' \leq 1 \label{eq:objective_function}
\end{align}

And in this simple abstracted way we get a sample packing LP from our dataset.

\subsubsection{Scenario}
To elucidate the core concepts,
suppose we have two relation $R$ and $S$ with attributes
\[
    Q(a, b, c) = R(a, b) \Join S(b, c)
\]
where we denote the sizes of the relations as
$|R|$ and $|S|$ respectively.
It is easy to see that the largest possible output is $|R| \cdot |S|$, which occurs when the join
behaves like a cartesian product, i.e. have a selectivity equals to 1. So, this is the worst-case
upper bound.
\subsubsection{Variables}
\subsubsection{Objective}
\subsubsection{Constraints}

\section{State-of-the-art LP solvers}
Here we will discuss alternative approaches that are used today to solve LPs. Nowadays, the best
existing open-source and commercial LP-systems are based on implementations that make use
of various algorithms and techniques to speed up the solution of large scale LP problems.
There exist various LP solvers today, like CPLEX (IBM), CBC, Gurobi, HIGHS... We present HIGHS Scipy, and
Cplex, because we are using them as a comparison to our solvers.
\subsection{HIGHS Scipy}
HiGHS, or High Performance Optimization Software is a software used to define,
modify and solve large scale sparse linear optimization models.

For LPs, HiGHS has implementations of both the revised simplex and interior point methods
\parencite{Huangfu2018}.
HiGHS has primal and
dual revised simplex solvers, originally written by Qi Huangfu and
further developed by Julian Hall.
In our comparison, we don't make use of HiGHS directly but of Scipy's linprog, and using as
a method highs. It is mainly used to verify the accuracy of the optimal values
obtained by our solvers.

\begin{lstlisting}[language=Python]
    linprog(method='highs')
\end{lstlisting}

\subsection{Cplex}
IBM ILOG CPLEX Optimization Studio, commonly known as CPLEX,
is a software suite for mathematical optimization.
CPLEX consists of a library for linear programming,
mixed integer programming, quadratic programming, and other optimization problems.

CPLEX utilizes a variety of algorithms to tackle linear programming (LP) problems.
Although the majority of LP instances are efficiently solved using CPLEX's
cutting-edge dual simplex algorithm, there are cases where other algorithms might be more suitable.
For certain problem types, the primal simplex algorithm, the network optimizer, the barrier algorithm,
or the sifting algorithm are used. 

Furthermore, CPLEX provides a concurrent option, which runs multiple algorithms in parallel,
returning the solution from the first algorithm to complete.
It also supports various interfaces, including C++, Java, and Python. In our experiments
we use the python interface.
CPLEX is widely used in both academia and industry for solving large-scale optimization
problems.
